## 一个 instance = 一组 filter + 一个 severity
## 需要不同严重级别？配多个 instance 即可
## ===== 最小可用示例（30 秒跑起来）=====
## 1) filter_include 填你的关键字（支持 glob + /regex/）
## 2) severity 设为 Warning 或 Critical
## 3) Linux 上直接生效（依赖 journalctl）
## 例子：
## filter_include = ["*Out of memory*", "/(?i)panic|segfault/"]
## [instances.match]
## severity = "Warning"
## 常见误区：
## - 仅支持 Linux（依赖 journalctl）
## - filter_include 不能为空
## - 一条 include 规则写成 /.../ 才是正则，否则按 glob 处理

## 示例1：常规异常日志 → Warning
[[instances]]
## journalctl 原生预过滤（性能最好，优先推荐）
## units：按 systemd 单元名过滤（可多个）
# units = ["nginx", "sshd", "docker"]

## priority：按日志级别过滤
##   单值："err"
##   范围："emerg..err"
##   数字："0..3"
priority = "emerg..err"

## 行级过滤（在原生预过滤之后执行）
## include 规则是 OR：任一规则命中即算匹配
## 支持 glob + 正则混用：
##   glob 示例：*Out of memory*
##   正则示例：/(?i)oom|segfault/
filter_include = [
    ## ── 内存 ──
    "*Out of memory*",          # 进程因内存不足被 OOM 杀死。排查：dmesg 看被杀进程，检查是否需要加内存或设置 memory cgroup 限制
    "*oom-killer*",             # OOM killer 被触发。排查：同上，关注 oom_score_adj 配置是否合理
    "*Killed process*",         # OOM killer 杀进程的另一种消息格式
    "*page allocation failure*", # 内核无法分配内存页。排查：检查内存碎片（buddyinfo）和 vm.min_free_kbytes 设置

    ## ── 内核崩溃/BUG ──
    "*kernel panic*",           # 内核崩溃，系统不可用。排查：收集 vmcore（kdump），分析 crash dump
    "*kernel BUG*",             # 内核代码触发 BUG() 断言。排查：检查内核版本，搜索对应 BUG 的补丁，考虑升级内核
    "*soft lockup*",            # CPU 被内核代码长时间占用（>20s）。排查：检查是否有内核模块死循环，dmesg 中的 Call Trace 定位卡点
    "*hard lockup*",            # CPU 完全无响应，NMI watchdog 检测到。排查：通常是硬件或驱动问题，检查 BIOS/固件更新

    ## ── CPU/硬件故障 ──
    "*machine check*",          # MCE：CPU/内存硬件故障。排查：mcelog 或 rasdaemon 查看详情，定位故障 DIMM 或 CPU，准备更换硬件
    "*Hardware Error*",         # 通用硬件错误（GHES/EDAC 报告）。排查：rasdaemon 查看错误类型，关注是否 correctable

    ## ── 进程异常 ──
    "*segfault*",               # 用户态段错误（非法内存访问）。排查：检查对应进程是否有 coredump，用 gdb/addr2line 分析
    "*dumped core*",            # 进程产生核心转储。排查：coredumpctl list 查看详情，分析 coredump 定位 crash 原因

    ## ── 磁盘/文件系统 ──
    "*I/O error*",              # 块设备 I/O 失败。排查：smartctl 检查磁盘健康，dmesg 看具体设备号，准备更换磁盘
    "*medium error*",           # SCSI/SATA 坏扇区。排查：smartctl -a 看 Reallocated_Sector_Ct，若持续增长需更换磁盘
    "*EXT4-fs error*",          # ext4 文件系统错误。排查：umount 后 fsck 修复，检查底层磁盘是否有坏道
    "*XFS error*",              # XFS 文件系统错误。排查：xfs_repair 修复，检查底层磁盘健康
    "*Read-only file system*",  # 文件系统降级为只读（通常因磁盘/fs 错误触发）。排查：检查 dmesg 中前序错误，修复后 remount

    ## ── 网络 ──
    "*nf_conntrack: table full*", # 连接跟踪表满，新连接被丢弃。排查：sysctl net.netfilter.nf_conntrack_max 调大，或优化连接超时
    "*neighbour table overflow*", # ARP/邻居表满，新 IP 无法通信（K8s 大集群高发）。排查：sysctl net.ipv4.neigh.default.gc_thresh3 调大
]
## exclude 为排除规则（优先级高于 include）
# filter_exclude = ["*expected*"]

## 告警描述中最多展示多少条命中日志（默认 10）
max_lines = 10

## journalctl 执行超时（默认 30s）
timeout = "30s"

## Gather interval
interval = "30s"

[instances.match]
severity = "Warning"
# title_rule = "[check] [target]"

[instances.alerting]
for_duration = 0
repeat_interval = "5m"
repeat_number = 3
# disabled = false
# disable_recovery_notification = false

## 示例2：致命错误 → Critical（独立 instance，独立告警）
# [[instances]]
# filter_include = ["*kernel panic*", "/(?i)segfault|oom.killer/"]
# interval = "30s"
# [instances.match]
# severity = "Critical"
# [instances.alerting]
# repeat_interval = "1m"
# repeat_number = 10
